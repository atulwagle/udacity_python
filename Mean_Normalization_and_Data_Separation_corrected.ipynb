{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EiwMJJG8Sgzl"
   },
   "source": [
    "# Mean Normalization\n",
    "\n",
    "In machine learning we use large amounts of data to train our models. Some machine learning algorithms may require that the data is *normalized* in order to work correctly. The idea of normalization, also known as *feature scaling*, is to ensure that all the data is on a similar scale, *i.e.* that all the data takes on a similar range of values. For example, we might have a dataset that has values between 0 and 5,000. By normalizing the data we can make the range of values be between 0 and 1.\n",
    "\n",
    "In this lab, you will be performing a different kind of feature scaling known as *mean normalization*. Mean normalization will scale the data, but instead of making the values be between 0 and 1, it will distribute the values evenly in some small interval around zero. For example, if we have a dataset that has values between 0 and 5,000, after mean normalization the range of values will be distributed in some small range around 0, for example between -3 to 3. Because the range of values are distributed evenly around zero, this guarantees that the average (mean) of all elements will be zero. Therefore, when you perform *mean normalization* your data will not only be scaled but it will also have an average of zero. \n",
    "\n",
    "# To Do:\n",
    "\n",
    "You will start by importing NumPy and creating a rank 2 ndarray of random integers between 0 and 5,000 (inclusive) with 1000 rows and 20 columns. This array will simulate a dataset with a wide range of values. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "AOs0DP2mSgzn",
    "outputId": "d08862fe-e344-4d33-c1ec-f36475ebcee1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3751 3698 1368 ... 1751 2100 4198]\n",
      " [  50 2061 1723 ... 2886 1295 3429]\n",
      " [4727 3901   19 ... 4263   45 3666]\n",
      " ...\n",
      " [2044 1383 2717 ... 1097 4493 1912]\n",
      " [4067 2807 4050 ... 4716 3338 4690]\n",
      " [ 850 3666 3107 ... 4562 3736 2959]]\n"
     ]
    }
   ],
   "source": [
    "# import NumPy into Python\n",
    "import numpy as np\n",
    "\n",
    "# Create a 1000 x 20 ndarray with random integers in the half-open interval [0, 5001).\n",
    "X =  np.random.randint(0,5001,size=(1000,20))\n",
    "\n",
    "# print the shape of X\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VCxP9s6ISgzy"
   },
   "source": [
    "Now that you created the array we will mean normalize it. We will perform mean normalization using the following equation:\n",
    "\n",
    "$\\mbox{Norm_Col}_i = \\frac{\\mbox{Col}_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "where $\\mbox{Col}_i$ is the $i$th column of $X$, $\\mu_i$ is average of the values in the $i$th column of $X$, and $\\sigma_i$ is the standard deviation of the values in the $i$th column of $X$. In other words, mean normalization is performed by subtracting from each column of $X$ the average of its values, and then by dividing by the standard deviation of its values. In the space below, you will first calculate the average and standard deviation of each column of $X$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cD0HSKsySgz1"
   },
   "outputs": [],
   "source": [
    "# Average of the values in each column of X\n",
    "ave_cols = X.mean(axis=0)\n",
    "\n",
    "# Standard Deviation of the values in each column of X\n",
    "std_cols = X.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ZxfzOmRSgz4"
   },
   "source": [
    "If you have done the above calculations correctly, then `ave_cols` and `std_cols`, should both be vectors with shape `(20,)` since $X$ has 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "b-adLxcRSgz6",
    "outputId": "26617b60-926b-41d1-eb03-20be7228b660"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2459.481 2504.424 2587.354 2458.037 2409.019 2529.851 2532.697 2543.763\n",
      " 2451.532 2486.793 2518.736 2499.584 2392.423 2548.261 2509.006 2454.108\n",
      " 2485.529 2496.94  2536.005 2479.052]\n",
      "[1427.71882093 1405.74935683 1456.80996519 1464.96794901 1447.319077\n",
      " 1442.91365397 1437.59920186 1444.83397483 1421.35254071 1425.69347342\n",
      " 1457.17694749 1451.56455831 1463.74067378 1445.3911446  1423.30948566\n",
      " 1482.47827179 1486.56730798 1443.08389929 1434.34032258 1444.60611839]\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of ave_cols\n",
    "print(ave_cols)\n",
    "\n",
    "# Print the shape of std_cols\n",
    "print(std_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XqkLjrLvSg0D"
   },
   "source": [
    "You can now take advantage of Broadcasting to calculate the mean normalized version of $X$ in just one line of code using the equation above. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Xc4eDdcSg0E"
   },
   "outputs": [],
   "source": [
    "# Mean normalize X\n",
    "#DONT HAVE TO SPECIFY AS ave_cols[:]. ave_cols ALREADY MEANS THE ENTIRE ARRAY\n",
    "X_norm = (X[:, 0:] - ave_cols)/std_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Oj2JTqMSg0H"
   },
   "source": [
    "If you have performed the mean normalization correctly, then the average of all the elements in $X_{\\tiny{\\mbox{norm}}}$ should be close to zero, and they should be evenly distributed in some small interval around zero. You can verify this by filing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "id": "hED8slFtSg0I",
    "outputId": "da41c6c2-5b65-43d1-8511-e5ba7feb194d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.90460319  0.84906743 -0.83700279 ... -0.51690688 -0.30397598\n",
      "   1.18990774]\n",
      " [-1.68764393 -0.31543603 -0.59331966 ...  0.26960317 -0.86520959\n",
      "   0.65758271]\n",
      " [ 1.58821118  0.9934744  -1.76299865 ...  1.22380965 -1.73669035\n",
      "   0.82164127]\n",
      " ...\n",
      " [-0.29101038 -0.79774107  0.08899308 ... -0.97010299  1.3643868\n",
      "  -0.39253053]\n",
      " [ 1.12593529  0.21524178  1.00400604 ...  1.53772071  0.55913857\n",
      "   1.530485  ]\n",
      " [-1.12730951  0.82630377  0.35670129 ...  1.43100481  0.83661805\n",
      "   0.33223451]]\n",
      "[-1.72196441 -1.77800117 -1.77604084 -1.67446462 -1.66308801 -1.74359082\n",
      " -1.7617546  -1.75297857 -1.72478814 -1.7414634  -1.72781762 -1.71923735\n",
      " -1.63104233 -1.75956592 -1.75928428 -1.65473454 -1.66661071 -1.73028055\n",
      " -1.75481715 -1.71607469]\n",
      "[1.76611736 1.77312975 1.65542937 1.73448368 1.78812056 1.70775915\n",
      " 1.71626626 1.70001332 1.78806308 1.7585877  1.69661207 1.71912161\n",
      " 1.77871466 1.69417047 1.74662926 1.71664708 1.68607973 1.73244258\n",
      " 1.71716221 1.7388463 ]\n"
     ]
    }
   ],
   "source": [
    "# Print the average of all the values of X_norm\n",
    "print(X_norm)\n",
    "\n",
    "# Print the average of the minimum value in each column of X_norm\n",
    "print(X_norm.min(axis=0))\n",
    "\n",
    "# Print the average of the maximum value in each column of X_norm\n",
    "print(X_norm.max(axis=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0xWZdM6tSg0N"
   },
   "source": [
    "You should note that since $X$ was created using random integers, the above values will vary. \n",
    "\n",
    "# Data Separation\n",
    "\n",
    "After the data has been mean normalized, it is customary in machine learnig to split our dataset into three sets:\n",
    "\n",
    "1. A Training Set\n",
    "2. A Cross Validation Set\n",
    "3. A Test Set\n",
    "\n",
    "The dataset is usually divided such that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. \n",
    "\n",
    "In this part of the lab you will separate `X_norm` into a Training Set, Cross Validation Set, and a Test Set. Each data set will contain rows of `X_norm` chosen at random, making sure that we don't pick the same row twice. This will guarantee that all the rows of `X_norm` are chosen and randomly distributed among the three new sets.\n",
    "\n",
    "You will start by creating a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this by using the `np.random.permutation()` function. The `np.random.permutation(N)` function creates a random permutation of integers from 0 to `N - 1`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XAU_oQIrSg0P",
    "outputId": "6ab79791-57df-4ac5-98f3-021f960eec3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 3, 0, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a random permutation of integers 0 to 4\n",
    "np.random.permutation(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OaOlosA7Sg0W"
   },
   "source": [
    "# To Do\n",
    "\n",
    "In the space below create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this in one line of code by extracting the number of rows of `X_norm` using the `shape` attribute and then passing it to the  `np.random.permutation()` function. Remember the `shape` attribute returns a tuple with two numbers in the form `(rows,columns)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 958
    },
    "colab_type": "code",
    "id": "FvbnqMyrSg0X",
    "outputId": "87bc7156-f9e3-4bba-baf7-37ff4aceec4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[114   9 269 527 691 625 958 546  20 423 978 616  60 583 739 223 899 682\n",
      " 697 699 125 757 775 701 749 299 317 861   3 629 648 336 783 552 890 973\n",
      " 181 243 307 346 257 518 294 825 429  89 881 841 303 678 865 779 818 515\n",
      " 187 409 517 424  52 639 743 631 179 439 907 142 143 389 994 796 755  26\n",
      " 696 160 853 592 268 846 989 437 960 765 731 675 383 319 205 468 717  11\n",
      " 108 882 452 813 446  23 220 721 819 714  47 118 347   5 427  48 886 298\n",
      " 287 374 964 174 357 472 852 673 225 967  10  36 767 434 460 122 203 420\n",
      " 656 504 671 442   8 538  57 497  82 763 754 932 947  88 635 931 713 244\n",
      "  90 371  46 840 184 919 131 365 360 641 896 137 175  25 589  62 147 222\n",
      " 688 681 172 431 540 981 503 380 267 490 516 156 506 521 830 483 577 955\n",
      " 403 185  16 526 615 241 785  79 952 111 470 653 151  19 773 760 769 774\n",
      " 293 419  93 345 780 218 145 903 880 927 944 549 604 658 213 200 992  81\n",
      " 186 605 916  33 548 643 976 100 822 310 991 473 435 938 650 400 664  78\n",
      " 557 782 132 121 533  87  84  94 709  66 670 898 601 566  97 854 999 539\n",
      " 949 148 447 462  56 778 786 645 169 198 291 606 159 129 248 354 612 351\n",
      "  35 812 464 733 694 171 803 832 101 968 289  92 494 364 500 979 844 208\n",
      " 153 117 259  69 356 283 127  24 798 279 477 322 249 748 569 996 677 788\n",
      " 652 609 428 649 842 647 829 940 379 816 545 719 961 912 593 438 700 323\n",
      " 239 838 594 304 130 811 302 292 772 839 706 505 372  28 833 305 261 607\n",
      " 909 217 906 387 917 458 136 407 493 807 889 834 487 301 793 632 461 858\n",
      " 623 599 450 908 193 123 350 368 422 273 106 430 288 390 856 382 963  31\n",
      " 585  50 704 630 499 262 684 330 272  44 646 849 152 124 923 732 235 586\n",
      " 254 781  32 877 227 990  51 170 987 109 228 495 725 306 525 386 421  22\n",
      " 264 578 576 867 530  30 728 761 660 104 556 596 975 826 240 342 542 562\n",
      " 614 864 332 285  38 541 378 466 687 564 399 183  40 823 744 415 708 406\n",
      " 524 730 690 300 835 456 610 158 584 309 523  68 455 787 245 331 869 871\n",
      " 598 559 459 672 482 936 922 560  80 280 391 621 397   1 278 579  53  17\n",
      " 828 784 313 234 859 361 723 597 974 777 321 216 875 453 522 197 425 511\n",
      " 707 580 595 768  12 640 485 138 334 102 879 986 573 980 797 866 668  85\n",
      "   4 809 941 275 229 902 894 817 519 972 705 851 618 720 985  45 872 207\n",
      " 385 199 247 911 935 676 574  96 166 144 802 582 711  65 702 771 188 815\n",
      " 762  14 509 531 628 929 260 824 535 202 398 274 402 231 553 449 956 914\n",
      " 776 474 324 341 751 913 311 167 312 327 230 792 745 885 384 191 893 878\n",
      " 110 764 358 201 214 575 742 726 255 478  61 736 800 563 633 284  64 925\n",
      " 271 164 993  95 353 443  70 343 139 180 544 396 146 698 735 738 998 624\n",
      "  43 286 337 134 887 600 686 570 212  98 120 843  76 417 876 224 588 883\n",
      " 194 661  27 277  39 445  13 436 680 945 103 528 794 270 480 637 165 510\n",
      " 804 328 746 657 412 189 951 498 766 163  21 627 115 791 520 982 665  67\n",
      " 571 348 857 759 727 410  74 741 622 465 414  15 211  99 190 133 997 820\n",
      " 644 476 860 325 168 401 457 666 454 904 801 836 758  55  83 463 496 154\n",
      " 507  34 116 740 873 369 178 537 126 140 651 747 226 256 467  29 352 810\n",
      " 469 536 969  77 290 237   6 392 962 333 554 959 753 729 251 602 177 150\n",
      " 440 619 349 481 799 394 265 752 581 667 868 376 884 335 685 276 492 221\n",
      " 905 937 295 233 789 663 413 395 381 320 814 236 370 874 107   0 486 901\n",
      " 551 238 173 946 934 953 679 984 405 377 669 613 266 790 756 297 426 534\n",
      " 722  91 416 943 695 966 895  18 957 484 971 314 308 970  49 850  41 892\n",
      " 659  59 591 512 995 555 674 444 433  42  37 821 195 162 252 479 393 112\n",
      "  54 939 550 897 441 900 155 827 282  73 831 215 848 983 355 942 855 547\n",
      " 654 611 750 910 965 543 558 683 315 933 590 948 692   7 411 232 837 432\n",
      " 532 921 488 716  75 366 258 626 250 329 489 565 977 219 182 373 316 770\n",
      " 418 795 915 928  71 954 634 572 210 338 161 141 263 135 603 513 888 508\n",
      " 620 920 655 448 105 845 113 149 712 157 281 339 805 710 204 737 529 930\n",
      " 408 724 404 638 375 642 176 514 693 608 491 209 362 950 246 318 119 703\n",
      " 363 501 568 471 715 988 206 561 296  72 344 388 242 340  58 502 367 662\n",
      " 924 734 451 847 918 891  86 196 617 128 636 359 689 192 870 587 475 926\n",
      " 718   2 567 326 863  63 253 806 808 862]\n"
     ]
    }
   ],
   "source": [
    "# Create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n",
    "#INSTEAD OF HARDCODING IT TO 1000 MAKE IT MODULAR AS MENTIONED.\n",
    "row_indices = np.random.permutation(X_norm.shape[0])\n",
    "\n",
    "print(row_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FBys9_d6Sg0c"
   },
   "source": [
    "Now you can create the three datasets using the `row_indices` ndarray to select the rows that will go into each dataset. Rememeber that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. Each set requires just one line of code to create. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1445
    },
    "colab_type": "code",
    "id": "lq80JRfaSg0d",
    "outputId": "3b33e79d-9811-4ded-db1c-9c2c352a6012"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_indices: \n",
      " [114   9 269 527 691 625 958 546  20 423 978 616  60 583 739 223 899 682\n",
      " 697 699 125 757 775 701 749 299 317 861   3 629 648 336 783 552 890 973\n",
      " 181 243 307 346 257 518 294 825 429  89 881 841 303 678 865 779 818 515\n",
      " 187 409 517 424  52 639 743 631 179 439 907 142 143 389 994 796 755  26\n",
      " 696 160 853 592 268 846 989 437 960 765 731 675 383 319 205 468 717  11\n",
      " 108 882 452 813 446  23 220 721 819 714  47 118 347   5 427  48 886 298\n",
      " 287 374 964 174 357 472 852 673 225 967  10  36 767 434 460 122 203 420\n",
      " 656 504 671 442   8 538  57 497  82 763 754 932 947  88 635 931 713 244\n",
      "  90 371  46 840 184 919 131 365 360 641 896 137 175  25 589  62 147 222\n",
      " 688 681 172 431 540 981 503 380 267 490 516 156 506 521 830 483 577 955\n",
      " 403 185  16 526 615 241 785  79 952 111 470 653 151  19 773 760 769 774\n",
      " 293 419  93 345 780 218 145 903 880 927 944 549 604 658 213 200 992  81\n",
      " 186 605 916  33 548 643 976 100 822 310 991 473 435 938 650 400 664  78\n",
      " 557 782 132 121 533  87  84  94 709  66 670 898 601 566  97 854 999 539\n",
      " 949 148 447 462  56 778 786 645 169 198 291 606 159 129 248 354 612 351\n",
      "  35 812 464 733 694 171 803 832 101 968 289  92 494 364 500 979 844 208\n",
      " 153 117 259  69 356 283 127  24 798 279 477 322 249 748 569 996 677 788\n",
      " 652 609 428 649 842 647 829 940 379 816 545 719 961 912 593 438 700 323\n",
      " 239 838 594 304 130 811 302 292 772 839 706 505 372  28 833 305 261 607\n",
      " 909 217 906 387 917 458 136 407 493 807 889 834 487 301 793 632 461 858\n",
      " 623 599 450 908 193 123 350 368 422 273 106 430 288 390 856 382 963  31\n",
      " 585  50 704 630 499 262 684 330 272  44 646 849 152 124 923 732 235 586\n",
      " 254 781  32 877 227 990  51 170 987 109 228 495 725 306 525 386 421  22\n",
      " 264 578 576 867 530  30 728 761 660 104 556 596 975 826 240 342 542 562\n",
      " 614 864 332 285  38 541 378 466 687 564 399 183  40 823 744 415 708 406\n",
      " 524 730 690 300 835 456 610 158 584 309 523  68 455 787 245 331 869 871\n",
      " 598 559 459 672 482 936 922 560  80 280 391 621 397   1 278 579  53  17\n",
      " 828 784 313 234 859 361 723 597 974 777 321 216 875 453 522 197 425 511\n",
      " 707 580 595 768  12 640 485 138 334 102 879 986 573 980 797 866 668  85\n",
      "   4 809 941 275 229 902 894 817 519 972 705 851 618 720 985  45 872 207\n",
      " 385 199 247 911 935 676 574  96 166 144 802 582 711  65 702 771 188 815\n",
      " 762  14 509 531 628 929 260 824 535 202 398 274 402 231 553 449 956 914\n",
      " 776 474 324 341 751 913 311 167 312 327 230 792 745 885 384 191 893 878\n",
      " 110 764 358 201 214 575]\n",
      "cross_val_indices: \n",
      " [742 726 255 478  61 736 800 563 633 284  64 925 271 164 993  95 353 443\n",
      "  70 343 139 180 544 396 146 698 735 738 998 624  43 286 337 134 887 600\n",
      " 686 570 212  98 120 843  76 417 876 224 588 883 194 661  27 277  39 445\n",
      "  13 436 680 945 103 528 794 270 480 637 165 510 804 328 746 657 412 189\n",
      " 951 498 766 163  21 627 115 791 520 982 665  67 571 348 857 759 727 410\n",
      "  74 741 622 465 414  15 211  99 190 133 997 820 644 476 860 325 168 401\n",
      " 457 666 454 904 801 836 758  55  83 463 496 154 507  34 116 740 873 369\n",
      " 178 537 126 140 651 747 226 256 467  29 352 810 469 536 969  77 290 237\n",
      "   6 392 962 333 554 959 753 729 251 602 177 150 440 619 349 481 799 394\n",
      " 265 752 581 667 868 376 884 335 685 276 492 221 905 937 295 233 789 663\n",
      " 413 395 381 320 814 236 370 874 107   0 486 901 551 238 173 946 934 953\n",
      " 679 984]\n",
      "test_indices: \n",
      " [405 377 669 613 266 790 756 297 426 534 722  91 416 943 695 966 895  18\n",
      " 957 484 971 314 308 970  49 850  41 892 659  59 591 512 995 555 674 444\n",
      " 433  42  37 821 195 162 252 479 393 112  54 939 550 897 441 900 155 827\n",
      " 282  73 831 215 848 983 355 942 855 547 654 611 750 910 965 543 558 683\n",
      " 315 933 590 948 692   7 411 232 837 432 532 921 488 716  75 366 258 626\n",
      " 250 329 489 565 977 219 182 373 316 770 418 795 915 928  71 954 634 572\n",
      " 210 338 161 141 263 135 603 513 888 508 620 920 655 448 105 845 113 149\n",
      " 712 157 281 339 805 710 204 737 529 930 408 724 404 638 375 642 176 514\n",
      " 693 608 491 209 362 950 246 318 119 703 363 501 568 471 715 988 206 561\n",
      " 296  72 344 388 242 340  58 502 367 662 924 734 451 847 918 891  86 196\n",
      " 617 128 636 359 689 192 870 587 475 926 718   2 567 326 863  63 253 806\n",
      " 808 862]\n",
      "X_train: \n",
      " [[ 828 2838   41 ...  251 3999 1767]\n",
      " [2090 1676  331 ... 1646 4498 4518]\n",
      " [2616 4987 2465 ...  446 3392 1202]\n",
      " ...\n",
      " [1745 2068 3540 ... 3286 2174  671]\n",
      " [4796 2911 4257 ... 2121  540 1065]\n",
      " [ 484 3320  698 ...   22 3019 2636]]\n",
      "X_crossVal: \n",
      " [[ 320 2265 1712 ...   49 3781 2939]\n",
      " [ 300 4035 4969 ... 2825 4903 4827]\n",
      " [4414 1428 2552 ... 2876 4425 4041]\n",
      " ...\n",
      " [4095  617 1719 ... 4997 2393 1764]\n",
      " [2319 2413 2558 ... 3136 4255  472]\n",
      " [ 248 1364 2243 ... 3897  981 1897]]\n",
      "X_test: \n",
      " [[1843 4828 2514 ... 3089 2073 2323]\n",
      " [ 311  648 2737 ...  806 4411 4408]\n",
      " [1422 4443 2021 ... 2677  750 4767]\n",
      " ...\n",
      " [2087 3792 1806 ... 1543 4263 2375]\n",
      " [4619 2891 1639 ... 1408 4678 4688]\n",
      " [1740 1707 3158 ... 1870  697 2793]]\n"
     ]
    }
   ],
   "source": [
    "# Make any necessary calculations.\n",
    "# You can save your calculations into variables to use later.\n",
    "\n",
    "#MAKE IT MODULAR :\n",
    "total_sample_size=X_norm.shape[0]\n",
    "\n",
    "train_portion,cross_valid_portion,test_portion=(int(total_sample_size*0.6),int(total_sample_size*0.2),int(total_sample_size*0.2))\n",
    "\n",
    "\n",
    "#INSTEAD OF GIVING HARDCODED VALUES MADE IT MODULAR. NOW IT CAN HANDLE NOT ONLY 1000 BUT 100,10K,100 MIL, ....ETC.\n",
    "#WE DONT HAVE TO REWRITE THE INDEX VALUES EVERYTIME\n",
    "\n",
    "train_indices = row_indices[:train_portion]\n",
    "print(\"train_indices: \\n\", train_indices)\n",
    "cross_val_indices = row_indices[train_portion:train_portion+cross_valid_portion]\n",
    "print(\"cross_val_indices: \\n\", cross_val_indices)\n",
    "test_indices = row_indices[train_portion+cross_valid_portion:]\n",
    "print(\"test_indices: \\n\", test_indices)\n",
    "\n",
    "# Create a Training Set\n",
    "X_train = X[train_indices]\n",
    "print(\"X_train: \\n\", X_train)\n",
    "\n",
    "# Create a Cross Validation Set\n",
    "X_crossVal = X[cross_val_indices]\n",
    "print(\"X_crossVal: \\n\", X_crossVal)\n",
    "\n",
    "# Create a Test Set\n",
    "X_test = X[test_indices]\n",
    "print(\"X_test: \\n\", X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iROCD-j9Sg0l"
   },
   "source": [
    "If you performed the above calculations correctly, then `X_tain` should have 600 rows and 20 columns, `X_crossVal` should have 200 rows and 20 columns, and `X_test` should have 200 rows and 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "1ncpgj6kSg0m",
    "outputId": "b6be222c-c7c9-4dc4-e66a-5d426cd3a1a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      " [[ 828 2838   41 ...  251 3999 1767]\n",
      " [2090 1676  331 ... 1646 4498 4518]\n",
      " [2616 4987 2465 ...  446 3392 1202]\n",
      " ...\n",
      " [1745 2068 3540 ... 3286 2174  671]\n",
      " [4796 2911 4257 ... 2121  540 1065]\n",
      " [ 484 3320  698 ...   22 3019 2636]] \n",
      "Shape:  (600, 20)\n",
      "X_crossVal:\n",
      " [[ 320 2265 1712 ...   49 3781 2939]\n",
      " [ 300 4035 4969 ... 2825 4903 4827]\n",
      " [4414 1428 2552 ... 2876 4425 4041]\n",
      " ...\n",
      " [4095  617 1719 ... 4997 2393 1764]\n",
      " [2319 2413 2558 ... 3136 4255  472]\n",
      " [ 248 1364 2243 ... 3897  981 1897]] \n",
      "Shape:  (200, 20)\n",
      "X_test:\n",
      " [[1843 4828 2514 ... 3089 2073 2323]\n",
      " [ 311  648 2737 ...  806 4411 4408]\n",
      " [1422 4443 2021 ... 2677  750 4767]\n",
      " ...\n",
      " [2087 3792 1806 ... 1543 4263 2375]\n",
      " [4619 2891 1639 ... 1408 4678 4688]\n",
      " [1740 1707 3158 ... 1870  697 2793]] \n",
      "Shape:  (200, 20)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of X_train\n",
    "print(\"X_train:\\n\", X_train, \"\\nShape: \", X_train.shape)\n",
    "\n",
    "# Print the shape of X_crossVal\n",
    "print(\"X_crossVal:\\n\", X_crossVal, \"\\nShape: \", X_crossVal.shape)\n",
    "\n",
    "# Print the shape of X_test\n",
    "print(\"X_test:\\n\", X_test, \"\\nShape: \", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OpZ-GUAhSg0s"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Mean Normalization and Data Separation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
