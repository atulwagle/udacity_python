{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Normalization\n",
    "\n",
    "In machine learning we use large amounts of data to train our models. Some machine learning algorithms may require that the data is *normalized* in order to work correctly. The idea of normalization, also known as *feature scaling*, is to ensure that all the data is on a similar scale, *i.e.* that all the data takes on a similar range of values. For example, we might have a dataset that has values between 0 and 5,000. By normalizing the data we can make the range of values be between 0 and 1.\n",
    "\n",
    "In this lab, you will be performing a different kind of feature scaling known as *mean normalization*. Mean normalization will scale the data, but instead of making the values be between 0 and 1, it will distribute the values evenly in some small interval around zero. For example, if we have a dataset that has values between 0 and 5,000, after mean normalization the range of values will be distributed in some small range around 0, for example between -3 to 3. Because the range of values are distributed evenly around zero, this guarantees that the average (mean) of all elements will be zero. Therefore, when you perform *mean normalization* your data will not only be scaled but it will also have an average of zero. \n",
    "\n",
    "# To Do:\n",
    "\n",
    "You will start by importing NumPy and creating a rank 2 ndarray of random integers between 0 and 5,000 (inclusive) with 1000 rows and 20 columns. This array will simulate a dataset with a wide range of values. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3004 1200 2443 ... 4742 4398 4499]\n",
      " [1648 4172 2975 ... 3589 1942 2481]\n",
      " [4907   33 1203 ...  212  496  299]\n",
      " ...\n",
      " [3249  904 4347 ... 3169 2618 2741]\n",
      " [3203  371 2229 ... 1422 1909  712]\n",
      " [2399  411 4435 ... 1440 1326  401]]\n"
     ]
    }
   ],
   "source": [
    "# import NumPy into Python\n",
    "import numpy as np\n",
    "\n",
    "# Create a 1000 x 20 ndarray with random integers in the half-open interval [0, 5001).\n",
    "X =  np.random.randint(0,5001,size=(1000,20))\n",
    "\n",
    "# print the shape of X\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you created the array we will mean normalize it. We will perform mean normalization using the following equation:\n",
    "\n",
    "$\\mbox{Norm_Col}_i = \\frac{\\mbox{Col}_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "where $\\mbox{Col}_i$ is the $i$th column of $X$, $\\mu_i$ is average of the values in the $i$th column of $X$, and $\\sigma_i$ is the standard deviation of the values in the $i$th column of $X$. In other words, mean normalization is performed by subtracting from each column of $X$ the average of its values, and then by dividing by the standard deviation of its values. In the space below, you will first calculate the average and standard deviation of each column of $X$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average of the values in each column of X\n",
    "ave_cols = X.mean(axis=0)\n",
    "\n",
    "# Standard Deviation of the values in each column of X\n",
    "std_cols = X.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have done the above calculations correctly, then `ave_cols` and `std_cols`, should both be vectors with shape `(20,)` since $X$ has 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2527.817 2516.539 2453.076 2616.354 2489.822 2546.48  2460.484 2578.886\n",
      " 2499.126 2404.758 2522.705 2444.179 2577.582 2408.304 2497.4   2526.773\n",
      " 2504.508 2464.802 2451.978 2563.649]\n",
      "[1472.85209832 1423.10159738 1400.50619928 1476.11224529 1418.20104792\n",
      " 1443.25431771 1430.80705818 1421.56867122 1453.18261142 1448.6375259\n",
      " 1453.63773891 1422.28679772 1462.309175   1397.76294828 1450.20624257\n",
      " 1495.21766558 1473.1397184  1426.97989572 1425.14978073 1477.49396811]\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of ave_cols\n",
    "print(ave_cols)\n",
    "\n",
    "# Print the shape of std_cols\n",
    "print(std_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now take advantage of Broadcasting to calculate the mean normalized version of $X$ in just one line of code using the equation above. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean normalize X\n",
    "X_norm = (X[:, 0:] - ave_cols[:])/std_cols[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have performed the mean normalization correctly, then the average of all the elements in $X_{\\tiny{\\mbox{norm}}}$ should be close to zero, and they should be evenly distributed in some small interval around zero. You can verify this by filing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.32330673 -0.92511947 -0.00719454 ...  1.59581646  1.36548595\n",
      "   1.30988758]\n",
      " [-0.59735597  1.16327675  0.37266811 ...  0.78781628 -0.35784169\n",
      "  -0.05593864]\n",
      " [ 1.61535771 -1.74515931 -0.89258869 ... -1.57872021 -1.37247188\n",
      "  -1.53276362]\n",
      " ...\n",
      " [ 0.48965066 -1.13311587  1.3523139  ...  0.49348838  0.11649442\n",
      "   0.12003501]\n",
      " [ 0.45841874 -1.50764991 -0.15999644 ... -0.73077554 -0.38099715\n",
      "  -1.25323625]\n",
      " [-0.08746092 -1.47954229  1.41514832 ... -0.71816148 -0.79007696\n",
      "  -1.4637278 ]]\n",
      "[-1.70948393 -1.76553733 -1.74870772 -1.76839804 -1.75491479 -1.75955129\n",
      " -1.71545422 -1.80637492 -1.71700788 -1.65587178 -1.73062719 -1.71426677\n",
      " -1.74968607 -1.71867769 -1.72072077 -1.68990312 -1.70011572 -1.72238026\n",
      " -1.71559371 -1.73377967]\n",
      "[1.67782156 1.73526683 1.80714944 1.61142624 1.76715283 1.69098403\n",
      " 1.77418471 1.70101807 1.71752262 1.78667331 1.7035159  1.78573056\n",
      " 1.65451879 1.85202792 1.71534222 1.65208522 1.69399546 1.7759171\n",
      " 1.77947752 1.64829844]\n"
     ]
    }
   ],
   "source": [
    "# Print the average of all the values of X_norm\n",
    "print(X_norm)\n",
    "\n",
    "# Print the average of the minimum value in each column of X_norm\n",
    "print(X_norm.min(axis=0))\n",
    "\n",
    "# Print the average of the maximum value in each column of X_norm\n",
    "print(X_norm.max(axis=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should note that since $X$ was created using random integers, the above values will vary. \n",
    "\n",
    "# Data Separation\n",
    "\n",
    "After the data has been mean normalized, it is customary in machine learnig to split our dataset into three sets:\n",
    "\n",
    "1. A Training Set\n",
    "2. A Cross Validation Set\n",
    "3. A Test Set\n",
    "\n",
    "The dataset is usually divided such that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. \n",
    "\n",
    "In this part of the lab you will separate `X_norm` into a Training Set, Cross Validation Set, and a Test Set. Each data set will contain rows of `X_norm` chosen at random, making sure that we don't pick the same row twice. This will guarantee that all the rows of `X_norm` are chosen and randomly distributed among the three new sets.\n",
    "\n",
    "You will start by creating a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this by using the `np.random.permutation()` function. The `np.random.permutation(N)` function creates a random permutation of integers from 0 to `N - 1`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a random permutation of integers 0 to 4\n",
    "np.random.permutation(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "In the space below create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this in one line of code by extracting the number of rows of `X_norm` using the `shape` attribute and then passing it to the  `np.random.permutation()` function. Remember the `shape` attribute returns a tuple with two numbers in the form `(rows,columns)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 55  51 543 120 528 831 727 459 697 809 397 814 179 500 372 381 504 626\n",
      " 856 991 682 184  39 439 823 205 353  40 873 769 122 657 702 441  24 968\n",
      " 333 972 464 993 418 787 926 407 614 535 843 921 402 974 832 235 681 323\n",
      " 554 818 143 896 731  94 204 699 467 236  66 750 773  77 165 992 713 196\n",
      " 836  23 609 639 957 948 562 346 364 250 443 748 945  88 107 796 105 976\n",
      " 819 804 160 462 801 325 255 564 715 794 525  31 735 477 546 598 339 167\n",
      " 784 686 350 724 815 181 211  91 338 349 398 109  14 351 401 133 555 502\n",
      " 261 280 473 545 150 618 385 121 461 408 517 917 541 745 202 227 566 692\n",
      " 332 284 198 847 982 729  90 696  89 757 137 849 446 786  70  64 740 802\n",
      " 344 842 486 688 359 617 630 673  41   5 951 225 549 575 751 436 985 168\n",
      " 734 180 298 474 149 886 723 986 303 714 203 521 505 793 108 677 741 694\n",
      " 690 629 428 172 601  45 648 300 489 559 199 239 193 508 966 602 447  30\n",
      " 707 206 479 301 118 855 520 961 188 563 537 619  60 613 483 324 157 365\n",
      " 647 947 576 328 542 653 669 104 652 774  78 977 967 533 749 231 664 378\n",
      "   8 616 352 268 290 124 933 511 320 516 725 567 493 522 578 875 984 810\n",
      " 414  54 915 726  10 266  59 995 770 924 620 490 882 561 177 955 382 910\n",
      "  84 568 711  65 903 187 131 494 860 355 340 282 754 182 289 833 851 173\n",
      " 534 292  72 586 590 208  97 642  82 675  42  76  63 820 655 347 270 281\n",
      " 780 415 452 975 595  99  58 496 454 450 532 312 919 132 315 336 437  69\n",
      " 627 529 665 373 100 798 485 776 672 670 422 607 171 938 309 507 361 685\n",
      " 834  16 813 889 606 869 357 256  98 610 444 588 136 557 821 259 898 879\n",
      " 481 296 765  67 271 840 426 577 189 343 625  49 432 512 874 658 775 964\n",
      " 101 530 641 178 747 942   9 716 245 425 469 345 939 981 990 214 246 392\n",
      "   1 463 480 316 434 488 599 963 703  85 841 797 706 867 674 861 374 237\n",
      " 217 201 475 662 497  21 668 644 275  32 671 306 582  20  87 742 356 140\n",
      " 983 503 263 922 808 476 322 226 850 928  73 795 210 649 430 295 260  11\n",
      " 273 839 971 215 224 876 491 646 893 687 388  95 920 142 380 587 327 544\n",
      " 759 413 762 403 852 307 310 901 334 746   4 518 638 495 684 470 412 868\n",
      " 523  26 302 431  48 186 509 130 449 570 811 591  36 299 615 539 536 377\n",
      " 892 663 277 853 596  92 888 169 272 394 341 778 783 115 472 458 145  83\n",
      " 969 387 604 994 805 900 816 308  34 390 600 755 965 117 698 423 848 633\n",
      " 191 766 932 721 927 501 123 637  22 409 134 445 640 752 636  74 608 197\n",
      " 622 248 238  68 634 112 790 242 424 556 482 391 484 212 286 375   7 384\n",
      " 252 379 216 654 420 777 141 912 207 788 175 911 183 705 163 872 905 229\n",
      " 858 114 930 650 656 970 825 987 785 129 710 538 153 934 937 297 838 274\n",
      " 487 550 335 854 348 524 234 753 594 368 829 185 683 429 884 761 589 772\n",
      " 956  29 907 363 102  18 846 830 233 453 862 581 680 571 128 916  96 448\n",
      "  61 909  79 944 247 451 111  35 466 881  57 152 973 661 498 679 219 597\n",
      " 800 887 732   3 781 515 573 404  62 585  52 176 410 161 194 651 369 558\n",
      " 370 499  28 764 106 457 733 220 624 228 110 718 354  38 904 918 806 138\n",
      " 744 700 492 318 877 623 342 760  81 170 311 190 826 291 949 792 456 701\n",
      " 421 258 321 527  75 824 294 863 914 695  15 989 305 866 331 768 885 712\n",
      " 304 460  19 276 572 583 393  33 763 779 358 395 158 574 155 988 603 593\n",
      " 278 960 660 319 513 659 317 164 579 844 254 612 676 859 979   0 717 621\n",
      " 997 230 269 442 244 728 405 789 569 807  71 756 465 362 209 218 736 730\n",
      " 767 953 925 551  47 891 471 135 908 329 222 645 835 540 383 419 998 845\n",
      " 902  93 894 941  46 440 931 360 739 119 126 526 628 943 366 704 952 330\n",
      " 895 241 213 906 959   2 313 722 771 592 890 240 174 978 691 148 267 506\n",
      " 519 827 817 221  25 605 880 192   6 144  17 635 257 116 389 565 883 314\n",
      " 455  12 285 996 580 632 865 709 950 980 857 326 514  43 560 243 923  27\n",
      " 799 962 899 337 897 864 667 719 438 166 151 958 283 113 870 293 265  86\n",
      " 127 406  37 156 584 936 400 478 146 195 822 103  56  50 643 631 946 720\n",
      "  44 737 940 758 678 871 433 611 264 547 878 468 708 666 828 913 999 743\n",
      " 159 738  53 954  80 399 376 553 791 510 371 411 812 154 287 837 253 251\n",
      " 288 803 935 262 548 125 139 162 531 232 782 279 147 435 367 416 689 693\n",
      "  13 427 552 249 396 417 386 200 929 223]\n"
     ]
    }
   ],
   "source": [
    "# Create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n",
    "row_indices = np.random.permutation(1000)\n",
    "\n",
    "print(row_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create the three datasets using the `row_indices` ndarray to select the rows that will go into each dataset. Rememeber that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. Each set requires just one line of code to create. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_indices: \n",
      " [ 55  51 543 120 528 831 727 459 697 809 397 814 179 500 372 381 504 626\n",
      " 856 991 682 184  39 439 823 205 353  40 873 769 122 657 702 441  24 968\n",
      " 333 972 464 993 418 787 926 407 614 535 843 921 402 974 832 235 681 323\n",
      " 554 818 143 896 731  94 204 699 467 236  66 750 773  77 165 992 713 196\n",
      " 836  23 609 639 957 948 562 346 364 250 443 748 945  88 107 796 105 976\n",
      " 819 804 160 462 801 325 255 564 715 794 525  31 735 477 546 598 339 167\n",
      " 784 686 350 724 815 181 211  91 338 349 398 109  14 351 401 133 555 502\n",
      " 261 280 473 545 150 618 385 121 461 408 517 917 541 745 202 227 566 692\n",
      " 332 284 198 847 982 729  90 696  89 757 137 849 446 786  70  64 740 802\n",
      " 344 842 486 688 359 617 630 673  41   5 951 225 549 575 751 436 985 168\n",
      " 734 180 298 474 149 886 723 986 303 714 203 521 505 793 108 677 741 694\n",
      " 690 629 428 172 601  45 648 300 489 559 199 239 193 508 966 602 447  30\n",
      " 707 206 479 301 118 855 520 961 188 563 537 619  60 613 483 324 157 365\n",
      " 647 947 576 328 542 653 669 104 652 774  78 977 967 533 749 231 664 378\n",
      "   8 616 352 268 290 124 933 511 320 516 725 567 493 522 578 875 984 810\n",
      " 414  54 915 726  10 266  59 995 770 924 620 490 882 561 177 955 382 910\n",
      "  84 568 711  65 903 187 131 494 860 355 340 282 754 182 289 833 851 173\n",
      " 534 292  72 586 590 208  97 642  82 675  42  76  63 820 655 347 270 281\n",
      " 780 415 452 975 595  99  58 496 454 450 532 312 919 132 315 336 437  69\n",
      " 627 529 665 373 100 798 485 776 672 670 422 607 171 938 309 507 361 685\n",
      " 834  16 813 889 606 869 357 256  98 610 444 588 136 557 821 259 898 879\n",
      " 481 296 765  67 271 840 426 577 189 343 625  49 432 512 874 658 775 964\n",
      " 101 530 641 178 747 942   9 716 245 425 469 345 939 981 990 214 246 392\n",
      "   1 463 480 316 434 488 599 963 703  85 841 797 706 867 674 861 374 237\n",
      " 217 201 475 662 497  21 668 644 275  32 671 306 582  20  87 742 356 140\n",
      " 983 503 263 922 808 476 322 226 850 928  73 795 210 649 430 295 260  11\n",
      " 273 839 971 215 224 876 491 646 893 687 388  95 920 142 380 587 327 544\n",
      " 759 413 762 403 852 307 310 901 334 746   4 518 638 495 684 470 412 868\n",
      " 523  26 302 431  48 186 509 130 449 570 811 591  36 299 615 539 536 377\n",
      " 892 663 277 853 596  92 888 169 272 394 341 778 783 115 472 458 145  83\n",
      " 969 387 604 994 805 900 816 308  34 390 600 755 965 117 698 423 848 633\n",
      " 191 766 932 721 927 501 123 637  22 409 134 445 640 752 636  74 608 197\n",
      " 622 248 238  68 634 112 790 242 424 556 482 391 484 212 286 375   7 384\n",
      " 252 379 216 654 420 777]\n",
      "cross_val_indices: \n",
      " [141 912 207 788 175 911 183 705 163 872 905 229 858 114 930 650 656 970\n",
      " 825 987 785 129 710 538 153 934 937 297 838 274 487 550 335 854 348 524\n",
      " 234 753 594 368 829 185 683 429 884 761 589 772 956  29 907 363 102  18\n",
      " 846 830 233 453 862 581 680 571 128 916  96 448  61 909  79 944 247 451\n",
      " 111  35 466 881  57 152 973 661 498 679 219 597 800 887 732   3 781 515\n",
      " 573 404  62 585  52 176 410 161 194 651 369 558 370 499  28 764 106 457\n",
      " 733 220 624 228 110 718 354  38 904 918 806 138 744 700 492 318 877 623\n",
      " 342 760  81 170 311 190 826 291 949 792 456 701 421 258 321 527  75 824\n",
      " 294 863 914 695  15 989 305 866 331 768 885 712 304 460  19 276 572 583\n",
      " 393  33 763 779 358 395 158 574 155 988 603 593 278 960 660 319 513 659\n",
      " 317 164 579 844 254 612 676 859 979   0 717 621 997 230 269 442 244 728\n",
      " 405 789]\n",
      "test_indices: \n",
      " [569 807  71 756 465 362 209 218 736 730 767 953 925 551  47 891 471 135\n",
      " 908 329 222 645 835 540 383 419 998 845 902  93 894 941  46 440 931 360\n",
      " 739 119 126 526 628 943 366 704 952 330 895 241 213 906 959   2 313 722\n",
      " 771 592 890 240 174 978 691 148 267 506 519 827 817 221  25 605 880 192\n",
      "   6 144  17 635 257 116 389 565 883 314 455  12 285 996 580 632 865 709\n",
      " 950 980 857 326 514  43 560 243 923  27 799 962 899 337 897 864 667 719\n",
      " 438 166 151 958 283 113 870 293 265  86 127 406  37 156 584 936 400 478\n",
      " 146 195 822 103  56  50 643 631 946 720  44 737 940 758 678 871 433 611\n",
      " 264 547 878 468 708 666 828 913 999 743 159 738  53 954  80 399 376 553\n",
      " 791 510 371 411 812 154 287 837 253 251 288 803 935 262 548 125 139 162\n",
      " 531 232 782 279 147 435 367 416 689 693  13 427 552 249 396 417 386 200\n",
      " 929 223]\n",
      "X_train: \n",
      " [[2187  238 3994 ... 3413 2777  384]\n",
      " [4111 4670 1518 ... 1060 1723 2520]\n",
      " [1469   22 3776 ... 2433 1860 3692]\n",
      " ...\n",
      " [1755  322 2012 ... 4042 2241 2340]\n",
      " [1918 3428 3059 ... 4146 4328  169]\n",
      " [4998 1343 2028 ... 3308 3439  451]]\n",
      "X_crossVal: \n",
      " [[2895 3412 4270 ... 4833 4973 2994]\n",
      " [3342 3763 1402 ...  475  864 2833]\n",
      " [4520 2560 2810 ...  802 1739 4361]\n",
      " ...\n",
      " [1286  720 3611 ... 3363 2619 3602]\n",
      " [4117 3041   27 ... 3252  716 4609]\n",
      " [3153 3630 4444 ... 1948 1301 1696]]\n",
      "X_test: \n",
      " [[4973 2961 3809 ... 1816 3282 2284]\n",
      " [3233 4856 2950 ... 2568 4000 4957]\n",
      " [1741 4473 3539 ... 4484 4819  133]\n",
      " ...\n",
      " [4718  101 3669 ... 4335 2680  541]\n",
      " [3890 3124  748 ... 3180  165 2558]\n",
      " [4152 1924 3644 ... 3416 4177 3098]]\n"
     ]
    }
   ],
   "source": [
    "# Make any necessary calculations.\n",
    "# You can save your calculations into variables to use later.\n",
    "train_indices = row_indices[:600]\n",
    "print(\"train_indices: \\n\", train_indices)\n",
    "cross_val_indices = row_indices[600:800]\n",
    "print(\"cross_val_indices: \\n\", cross_val_indices)\n",
    "test_indices = row_indices[800:]\n",
    "print(\"test_indices: \\n\", test_indices)\n",
    "\n",
    "# Create a Training Set\n",
    "X_train = X[train_indices,:]\n",
    "print(\"X_train: \\n\", X_train)\n",
    "\n",
    "# Create a Cross Validation Set\n",
    "X_crossVal = X[cross_val_indices,:]\n",
    "print(\"X_crossVal: \\n\", X_crossVal)\n",
    "\n",
    "# Create a Test Set\n",
    "X_test = X[test_indices,:]\n",
    "print(\"X_test: \\n\", X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you performed the above calculations correctly, then `X_tain` should have 600 rows and 20 columns, `X_crossVal` should have 200 rows and 20 columns, and `X_test` should have 200 rows and 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      " [[2187  238 3994 ... 3413 2777  384]\n",
      " [4111 4670 1518 ... 1060 1723 2520]\n",
      " [1469   22 3776 ... 2433 1860 3692]\n",
      " ...\n",
      " [1755  322 2012 ... 4042 2241 2340]\n",
      " [1918 3428 3059 ... 4146 4328  169]\n",
      " [4998 1343 2028 ... 3308 3439  451]] \n",
      "Shape:  (600, 20)\n",
      "X_crossVal:\n",
      " [[2895 3412 4270 ... 4833 4973 2994]\n",
      " [3342 3763 1402 ...  475  864 2833]\n",
      " [4520 2560 2810 ...  802 1739 4361]\n",
      " ...\n",
      " [1286  720 3611 ... 3363 2619 3602]\n",
      " [4117 3041   27 ... 3252  716 4609]\n",
      " [3153 3630 4444 ... 1948 1301 1696]] \n",
      "Shape:  (200, 20)\n",
      "X_test:\n",
      " [[4973 2961 3809 ... 1816 3282 2284]\n",
      " [3233 4856 2950 ... 2568 4000 4957]\n",
      " [1741 4473 3539 ... 4484 4819  133]\n",
      " ...\n",
      " [4718  101 3669 ... 4335 2680  541]\n",
      " [3890 3124  748 ... 3180  165 2558]\n",
      " [4152 1924 3644 ... 3416 4177 3098]] \n",
      "Shape:  (200, 20)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of X_train\n",
    "print(\"X_train:\\n\", X_train, \"\\nShape: \", X_train.shape)\n",
    "\n",
    "# Print the shape of X_crossVal\n",
    "print(\"X_crossVal:\\n\", X_crossVal, \"\\nShape: \", X_crossVal.shape)\n",
    "\n",
    "# Print the shape of X_test\n",
    "print(\"X_test:\\n\", X_test, \"\\nShape: \", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
